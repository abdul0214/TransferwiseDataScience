{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1975,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data,n):\n",
    "    %matplotlib inline     \n",
    "    # allows to output plots in the notebook\n",
    "    plt.style.use(\"ggplot\")     # Set the default style\n",
    "    plt.rcParams['figure.dpi'] = 250\n",
    "    if (data.dtype !=  object) or (data.dtype !=  category):\n",
    "        plt.hist(data,  width = 0.5, \n",
    "                 weights = np.ones(len(data)) / len(data),\n",
    "                 bins=(np.arange(n+1)-0.2)+min(data) )\n",
    "    else:\n",
    "        plt.hist(data,  width = 0.5, \n",
    "                 weights = np.ones(len(data)) / len(data),\n",
    "                 bins=(np.arange(n+1)-0.2) )    \n",
    "    \n",
    "    plt.xticks(rotation=90,fontsize=8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_excel(r'cleaned_data.xlsx')\n",
    "cleaned_data.isnull().sum()\n",
    "combine = [cleaned_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>contract_start</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>maritalstatus</th>\n",
       "      <th>education</th>\n",
       "      <th>dependants</th>\n",
       "      <th>job</th>\n",
       "      <th>town</th>\n",
       "      <th>default</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>weekofmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>43</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>3</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>50</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>SECONDARY</td>\n",
       "      <td>3</td>\n",
       "      <td>ENTREPRENEUR</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>29</td>\n",
       "      <td>MALE</td>\n",
       "      <td>COHABITING</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Vestmannaeyjar</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>29</td>\n",
       "      <td>MALE</td>\n",
       "      <td>COHABITING</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Álftanes</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>28</td>\n",
       "      <td>MALE</td>\n",
       "      <td>COHABITING</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>1</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>7992</td>\n",
       "      <td>7993</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>71</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>0</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>7993</td>\n",
       "      <td>7994</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>61</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>HIGHER_BA</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Hafnarfjörður</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>7994</td>\n",
       "      <td>7995</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>42</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>0</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Akranes</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>7995</td>\n",
       "      <td>7996</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>27</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>HIGHER_BA</td>\n",
       "      <td>2</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>7996</td>\n",
       "      <td>7997</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>52</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>SECONDARY_SPECIALISED</td>\n",
       "      <td>1</td>\n",
       "      <td>EMPLOYEE</td>\n",
       "      <td>Reykjavík</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7990 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    id contract_start  age  gender maritalstatus  \\\n",
       "0              0     1     2018-01-04   43    MALE       MARRIED   \n",
       "1              1     2     2018-01-24   50  FEMALE       MARRIED   \n",
       "2              2     3     2018-01-02   29    MALE    COHABITING   \n",
       "3              3     4     2018-01-02   29    MALE    COHABITING   \n",
       "4              4     5     2018-01-02   28    MALE    COHABITING   \n",
       "...          ...   ...            ...  ...     ...           ...   \n",
       "7985        7992  7993     2019-01-31   71    MALE       MARRIED   \n",
       "7986        7993  7994     2019-01-31   61  FEMALE      DIVORCED   \n",
       "7987        7994  7995     2019-02-07   42    MALE       MARRIED   \n",
       "7988        7995  7996     2019-02-05   27  FEMALE        SINGLE   \n",
       "7989        7996  7997     2019-02-11   52  FEMALE      DIVORCED   \n",
       "\n",
       "                  education  dependants           job            town  \\\n",
       "0     SECONDARY_SPECIALISED           3      EMPLOYEE       Reykjavík   \n",
       "1                 SECONDARY           3  ENTREPRENEUR       Reykjavík   \n",
       "2     SECONDARY_SPECIALISED           0      EMPLOYEE  Vestmannaeyjar   \n",
       "3     SECONDARY_SPECIALISED           0      EMPLOYEE        Álftanes   \n",
       "4     SECONDARY_SPECIALISED           1      EMPLOYEE       Reykjavík   \n",
       "...                     ...         ...           ...             ...   \n",
       "7985  SECONDARY_SPECIALISED           0       RETIRED       Reykjavík   \n",
       "7986              HIGHER_BA           0      EMPLOYEE   Hafnarfjörður   \n",
       "7987  SECONDARY_SPECIALISED           0      EMPLOYEE         Akranes   \n",
       "7988              HIGHER_BA           2      EMPLOYEE       Reykjavík   \n",
       "7989  SECONDARY_SPECIALISED           1      EMPLOYEE       Reykjavík   \n",
       "\n",
       "      default       date  year  month  day  dayofyear  dayofweek  weekofyear  \\\n",
       "0           0 2018-01-04  2018      1    4          4          3           1   \n",
       "1           1 2018-01-24  2018      1   24         24          2           4   \n",
       "2           0 2018-01-02  2018      1    2          2          1           1   \n",
       "3           0 2018-01-02  2018      1    2          2          1           1   \n",
       "4           1 2018-01-02  2018      1    2          2          1           1   \n",
       "...       ...        ...   ...    ...  ...        ...        ...         ...   \n",
       "7985        0 2019-01-31  2019      1   31         31          3           5   \n",
       "7986        0 2019-01-31  2019      1   31         31          3           5   \n",
       "7987        0 2019-02-07  2019      2    7         38          3           6   \n",
       "7988        1 2019-02-05  2019      2    5         36          1           6   \n",
       "7989        0 2019-02-11  2019      2   11         42          0           7   \n",
       "\n",
       "      weekofmonth  \n",
       "0             1.0  \n",
       "1             4.0  \n",
       "2             1.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "...           ...  \n",
       "7985          5.0  \n",
       "7986          5.0  \n",
       "7987          2.0  \n",
       "7988          1.0  \n",
       "7989          2.0  \n",
       "\n",
       "[7990 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    \n",
    "    dataset['date'] = cleaned_data['contract_start']\n",
    "    dataset['year'] = dataset.date.dt.year\n",
    "    dataset['month'] = dataset.date.dt.month\n",
    "    dataset['day'] = dataset.date.dt.day\n",
    "    dataset['dayofyear'] = dataset.date.dt.dayofyear\n",
    "    dataset['dayofweek'] = dataset.date.dt.dayofweek\n",
    "    dataset['weekofyear'] = dataset.date.dt.weekofyear\n",
    "    dataset['weekofmonth'] = dataset['weekofyear']\n",
    "    dataset['weekofmonth'] = (dataset.date.dt.day/7) +1\n",
    "    dataset['weekofmonth'] = dataset['weekofmonth'].apply(np.floor)\n",
    "    display(dataset)\n",
    "    # Additional date features\n",
    "    dataset['log_dayofyear'] = np.log(dataset['dayofyear'])\n",
    "    dataset['day_power_year'] = np.log((np.log(dataset['dayofyear'] + 1)) ** (dataset['year'] - 2000))\n",
    "    dataset['day_week_power_year'] = np.log(np.log(dataset['dayofyear'] + 1) * (np.log(dataset['weekofyear'] + 1)) ** (dataset['year'] - 2000))\n",
    "    # Drop date\n",
    "    dataset.drop(['date'], axis=1, inplace=True)\n",
    "    dataset.drop(['contract_start'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1979,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['gender'] = dataset['gender'].astype('category')\n",
    "dataset['education'] = dataset['education'].astype('category')\n",
    "dataset['town'] = dataset['town'].astype('category')\n",
    "dataset['job'] = dataset['job'].astype('category')\n",
    "dataset['maritalstatus']= dataset['maritalstatus'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add features, such as average sales pr. day, average sales pr. month, rolling mean 90 periods\n",
    "# def add_avg(x):\n",
    "#     x['daily_avg']=x.groupby(['item','store','dayofweek'])['sales'].transform('mean')\n",
    "#     x['monthly_avg']=x.groupby(['item','store','month'])['sales'].transform('mean')\n",
    "#     return x\n",
    "\n",
    "# dataset = add_avg(dataset).dropna()\n",
    "# education_avg = train.groupby(['item','store','dayofweek'])['sales'].mean().reset_index()\n",
    "# monthly_avg = train.groupby(['item','store','month'])['sales'].mean().reset_index()\n",
    "\n",
    "# def merge(x,y,col,col_name):\n",
    "#     x =pd.merge(x, y, how='left', on=None, left_on=col, right_on=col,\n",
    "#             left_index=False, right_index=False, sort=True,\n",
    "#              copy=True, indicator=False,validate=None)\n",
    "#     x=x.rename(columns={'sales':col_name})\n",
    "#     return x\n",
    "\n",
    "# test = merge(test, daily_avg,['item','store','dayofweek'],'daily_avg')\n",
    "# test = merge(test, monthly_avg,['item','store','month'],'monthly_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded = pd.get_dummies(dataset, columns=['gender'], prefix = ['gender'])\n",
    "dataset_encoded = pd.get_dummies(dataset_encoded, columns=['education'], prefix = ['education'])\n",
    "dataset_encoded = pd.get_dummies(dataset_encoded, columns=['maritalstatus'], prefix = ['maritalstatus'])\n",
    "dataset_encoded = pd.get_dummies(dataset_encoded, columns=['job'], prefix = ['job'])\n",
    "dataset_encoded = pd.get_dummies(dataset_encoded, columns=['town'], prefix = ['town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1982,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_default = dataset_encoded['default']\n",
    "to_be_normailzed = dataset_encoded.select_dtypes(include=['int','float'])\n",
    "normalized = (to_be_normailzed - to_be_normailzed.mean()) / to_be_normailzed.std()\n",
    "dataset_encoded[list(normalized.columns)] = normalized\n",
    "dataset_encoded['default'] = temp_default\n",
    "#dataset_encoded['id'] = temp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded = dataset_encoded.loc[:, ~dataset_encoded.columns.str.contains('^Unnamed')]#dropping the unamed columns\n",
    "dataset_encoded = dataset_encoded.loc[:, dataset_encoded.columns != 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1984,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'dependants', 'year', 'month', 'day', 'dayofyear', 'dayofweek',\n",
       "       'weekofyear', 'weekofmonth', 'log_dayofyear', 'day_power_year',\n",
       "       'day_week_power_year', 'gender_FEMALE', 'gender_MALE',\n",
       "       'education_BASIC', 'education_HIGHER_BA', 'education_HIGHER_MA',\n",
       "       'education_HIGHER_PHD', 'education_SECONDARY',\n",
       "       'education_SECONDARY_SPECIALISED', 'maritalstatus_COHABITING',\n",
       "       'maritalstatus_DIVORCED', 'maritalstatus_MARRIED',\n",
       "       'maritalstatus_SINGLE', 'maritalstatus_WIDOW', 'job_EMPLOYEE',\n",
       "       'job_ENTREPRENEUR', 'job_PENSIONER', 'job_RETIRED', 'job_STUDENT',\n",
       "       'job_UNEMPLOYED', 'town_Akranes', 'town_Akureyri', 'town_Garðabær',\n",
       "       'town_Grindavík', 'town_Hafnarfjörður', 'town_Kópavogur',\n",
       "       'town_Mosfellsbær', 'town_Reykjavík', 'town_Sauðárkrókur',\n",
       "       'town_Selfoss', 'town_Seltjarnarnes', 'town_Vestmannaeyjar',\n",
       "       'town_Álftanes', 'town_Ísafjörður'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=dataset_encoded.drop('default',axis=1)\n",
    "y=dataset_encoded.pop('default')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1985,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# os = SMOTE(random_state=0)\n",
    "# columns = X_train.columns\n",
    "# X_train,y_train=os.fit_sample(X_train, y_train)\n",
    "# X_train = pd.DataFrame(data=X_train,columns=columns )\n",
    "# y_train = pd.DataFrame(data=y_train,columns=['default'])\n",
    "# # we can Check the numbers of our data\n",
    "# print(\"length of oversampled data is \",len(X_train))\n",
    "# print(\"Numbe invalid type promotionr of7736 no subscription in oversampled data\",len(y_train[y_train['default']==0]))\n",
    "# print(\"Number of subscription\",len(y_train[y_train['default']==1]))\n",
    "# print(\"Proportion of no subscription data in oversampled data is \",len(y_train[y_train['default']==0])/len(X_train))\n",
    "# print(\"Proportion of subscription data in oversampled data is \",len(y_train[y_train['default']==1])/len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1986,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Oversample and plot imbalanced dataset with SMOTE\n",
    "# from collections import Counter\n",
    "# from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from matplotlib import pyplot\n",
    "# from numpy import where\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline\n",
    "\n",
    "# over = SMOTE(sampling_strategy=0.4)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "\n",
    "\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "# X_train, y_train = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1987,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 1,\n",
    "                1: 3}\n",
    "penalty = 'l2' \n",
    "C=1\n",
    "max_iter=10000\n",
    "fit_intercept=False\n",
    "intercept_scaling=1\n",
    "multi_class='ovr'\n",
    "solver='lbfgs'\n",
    "class_weight=class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=1, Mean ROC AUC: 0.099\n",
      "> k=2, Mean ROC AUC: 0.099\n",
      "> k=3, Mean ROC AUC: 0.099\n",
      "> k=4, Mean ROC AUC: 0.098\n",
      "> k=5, Mean ROC AUC: 0.099\n",
      "> k=6, Mean ROC AUC: 0.098\n",
      "> k=7, Mean ROC AUC: 0.099\n"
     ]
    }
   ],
   "source": [
    "# grid search k value for SMOTE oversampling for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# define dataset\n",
    "# values to evaluate\n",
    "k_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model=LogisticRegression(\n",
    "                                class_weight = class_weights,\n",
    "                                C=C,\n",
    "                                max_iter=max_iter,\n",
    "                                fit_intercept=fit_intercept,\n",
    "                                intercept_scaling=intercept_scaling,\n",
    "                                multi_class=multi_class,\n",
    "                                solver=solver\n",
    "                                )\n",
    "\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    selector = SelectFromModel(estimator=model,threshold=0.1)\n",
    "\n",
    "    steps = [('over', over), ('under', under),('feature_selection',selector), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='precision', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['day', 'weekofyear', 'log_dayofyear', 'education_BASIC',\n",
      "       'maritalstatus_SINGLE', 'job_STUDENT', 'town_Akranes',\n",
      "       'town_Vestmannaeyjar'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_final_vars=dataset_encoded.columns.values.tolist()\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(\n",
    "                            class_weight = class_weights,\n",
    "                            C=C,\n",
    "                            max_iter=max_iter,\n",
    "                            fit_intercept=fit_intercept,\n",
    "                            intercept_scaling=intercept_scaling,\n",
    "                            multi_class=multi_class,\n",
    "                            solver=solver\n",
    "                            )\n",
    "logreg.fit(X_train,y_train)\n",
    "feature_idx=(np.round(logreg.coef_,decimals=3) > 0.1).tolist()[0]\n",
    "feature_name=X.columns[feature_idx]\n",
    "print(X.columns[feature_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1990,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[feature_name]\n",
    "X_test=X_test[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1991,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "model = LogisticRegression(\n",
    "                            class_weight = class_weights,\n",
    "                            C=C,\n",
    "                            max_iter=max_iter,\n",
    "                            fit_intercept=fit_intercept,\n",
    "                            intercept_scaling=intercept_scaling,\n",
    "                            multi_class=multi_class,\n",
    "                            solver=solver\n",
    "                            )\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1992,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight={0: 1, 1: 3}, dual=False,\n",
       "                   fit_intercept=False, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=10000, multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 1992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "logreg=LogisticRegression(\n",
    "                            class_weight = class_weights,\n",
    "                            C=C,\n",
    "                            max_iter=max_iter,\n",
    "                            fit_intercept=fit_intercept,\n",
    "                            intercept_scaling=intercept_scaling,\n",
    "                            multi_class=multi_class,\n",
    "                            solver=solver\n",
    "                            )\n",
    "\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1994,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "#y_pred = model.predict(X_test)\n",
    "#y_pred = np.argmax(y_pred, axis=-1)\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1995,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = (logreg.predict_proba(X_test) >= 0.55).astype(int)\n",
    "n = 1 # N. . .\n",
    "decisions = [x[n] for x in decisions]\n",
    "y_pred = decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1996,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "# print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       369\n",
      "           1       0.10      0.13      0.11        31\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.51      0.51      0.51       400\n",
      "weighted avg       0.86      0.84      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1998,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array((np.array(y_pred) > 0) ,dtype=bool)\n",
    "b=np.array((y_test > 0) ,dtype=bool)\n",
    "defaults_captured = 0\n",
    "defaults_missed = 0\n",
    "\n",
    "defaults_real = [i for i, x in enumerate(b) if x]\n",
    "defaults_pred = [i for i, x in enumerate(a) if x]\n",
    "undefaults_real = [i for i, x in enumerate(b) if (not(x))]\n",
    "undefaults_pred = [i for i, x in enumerate(a) if (not(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results we want to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1999,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision  0.0975609756097561\n",
      "recall  0.12903225806451613\n",
      "f1  0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "for elem in defaults_real:\n",
    "    if elem in defaults_pred:\n",
    "        true_positives += 1\n",
    "    else:\n",
    "        false_negatives += 1        \n",
    "        \n",
    "for elem in undefaults_real:\n",
    "    if elem in undefaults_pred:\n",
    "        true_negatives += 1\n",
    "    else:\n",
    "        false_positives += 1\n",
    "        \n",
    "precision =  true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "f1= 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "\n",
    "#print(\"true positives\", true_positives)\n",
    "#print(\"true negatives\", true_negatives)\n",
    "\n",
    "#print(\"false positives\", false_positives)\n",
    "#print(\"false negatives\", false_negatives)\n",
    "\n",
    "print (\"precision \", precision)\n",
    "print (\"recall \", recall)\n",
    "print(\"f1 \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
