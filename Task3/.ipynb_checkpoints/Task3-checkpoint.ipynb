{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree \n",
    "from sklearn import ensemble\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_white=pd.read_csv(r'winequality-white.csv',sep=None,engine='python')\n",
    "dataset_red=pd.read_csv(r'winequality-red.csv',sep=None,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "      <td>4898.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.854788</td>\n",
       "      <td>0.278241</td>\n",
       "      <td>0.334192</td>\n",
       "      <td>6.391415</td>\n",
       "      <td>0.045772</td>\n",
       "      <td>35.308085</td>\n",
       "      <td>138.360657</td>\n",
       "      <td>0.994027</td>\n",
       "      <td>3.188267</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>10.514267</td>\n",
       "      <td>5.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.843868</td>\n",
       "      <td>0.100795</td>\n",
       "      <td>0.121020</td>\n",
       "      <td>5.072058</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>17.007137</td>\n",
       "      <td>42.498065</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.151001</td>\n",
       "      <td>0.114126</td>\n",
       "      <td>1.230621</td>\n",
       "      <td>0.885639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.991723</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>10.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>3.280000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    4898.000000       4898.000000  4898.000000     4898.000000   \n",
       "mean        6.854788          0.278241     0.334192        6.391415   \n",
       "std         0.843868          0.100795     0.121020        5.072058   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.300000          0.210000     0.270000        1.700000   \n",
       "50%         6.800000          0.260000     0.320000        5.200000   \n",
       "75%         7.300000          0.320000     0.390000        9.900000   \n",
       "max        14.200000          1.100000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  4898.000000          4898.000000           4898.000000  4898.000000   \n",
       "mean      0.045772            35.308085            138.360657     0.994027   \n",
       "std       0.021848            17.007137             42.498065     0.002991   \n",
       "min       0.009000             2.000000              9.000000     0.987110   \n",
       "25%       0.036000            23.000000            108.000000     0.991723   \n",
       "50%       0.043000            34.000000            134.000000     0.993740   \n",
       "75%       0.050000            46.000000            167.000000     0.996100   \n",
       "max       0.346000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  4898.000000  4898.000000  4898.000000  4898.000000  \n",
       "mean      3.188267     0.489847    10.514267     5.877909  \n",
       "std       0.151001     0.114126     1.230621     0.885639  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.090000     0.410000     9.500000     5.000000  \n",
       "50%       3.180000     0.470000    10.400000     6.000000  \n",
       "75%       3.280000     0.550000    11.400000     6.000000  \n",
       "max       3.820000     1.080000    14.200000     9.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_white.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset_white['quality'].values\n",
    "X = dataset_white.drop(columns = ['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit(X_train).transform(X_train)\n",
    "X_test = StandardScaler().fit(X_test).transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(models,X_train,y_train,X_test,y_test):\n",
    "    names=[]\n",
    "    R2_trains=[]\n",
    "    R2_tests=[]\n",
    "    Train_maes=[]\n",
    "    Test_maes=[]\n",
    "    overfittings=[]\n",
    "    underfittings=[]\n",
    "    for model in models:\n",
    "\n",
    "        model = model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        name=model.__class__.__name__\n",
    "        R2_train=model.score(X_train, y_train)\n",
    "        R2_test=r2_score(y_test, y_pred)\n",
    "        Train_mae=mean_absolute_error(y_pred_train, y_train)\n",
    "        Test_mae=mean_absolute_error(y_test,y_pred)\n",
    "        \n",
    "        \n",
    "        Test_maes.append(Test_mae)\n",
    "        Train_maes.append(Train_mae)\n",
    "        R2_trains.append(R2_train)\n",
    "        R2_tests.append(R2_test)\n",
    "        names.append(name)\n",
    "        \n",
    "        if ((Test_mae-Train_mae>0.2) or (R2_train-R2_test>0.2)):\n",
    "            overfittings.append(name)\n",
    "        if (Train_mae>0.4) or (R2_train<0.2):\n",
    "            underfittings.append(name)\n",
    "        \n",
    "        print(\"\\n\\nModel:\", name)\n",
    "        print(\"\\nTrain r2_score  : \",R2_train)\n",
    "        print(\"Test  r2_score  : \",R2_test)\n",
    "        print(\"\\nTrain mae : \",Train_mae)\n",
    "        print(\"Test  mae : \",Test_mae)\n",
    "        \n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"Best   r2_train : \",  names[R2_trains.index(max(R2_trains))], \" \",max(R2_trains))\n",
    "    print(\"\\nBest   r2_test : \",  names[R2_tests.index(max(R2_tests))], \" \",max(R2_tests))\n",
    "    print(\"\\nBest Train  MAE : \",  names[Train_maes.index(min(Train_maes))], \" \",min(Train_maes))\n",
    "    print(\"\\nBest Test   MAE : \",  names[Test_maes.index(min(Test_maes))], \" \",min(Test_maes))\n",
    "    print(\"\\nModels with Over-fittings\",  overfittings)\n",
    "    print(\"\\nModels with Under-fittings\",  underfittings)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since we have multitask option available, we can fit both red wine and white wine models together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "R = Ridge()\n",
    "RCV = RidgeCV()\n",
    "SGD = SGDRegressor()\n",
    "L = linear_model.Lasso()\n",
    "EN = linear_model.ElasticNet()\n",
    "HR = linear_model.HuberRegressor()\n",
    "LSVR = sklearn.svm.LinearSVR(max_iter=10000)\n",
    "DTR = tree.DecisionTreeRegressor()\n",
    "ETR = tree.ExtraTreeRegressor()\n",
    "\n",
    "linear_models = [LR,R,RCV,SGD,L,EN,HR,LSVR,ETR,DTR]\n",
    "#linear_models = [LR,R,RCV,SGD,L,EN,HR,LSVR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model: LinearRegression\n",
      "\n",
      "Train r2  :  0.2879431225091068\n",
      "Test  r2  :  0.2506416786605612\n",
      "\n",
      "Train mae :  0.572938287720041\n",
      "Test  mae :  0.6314120523577407\n",
      "\n",
      "\n",
      "Model: Ridge\n",
      "\n",
      "Train r2  :  0.28794088486195923\n",
      "Test  r2  :  0.2509695974252484\n",
      "\n",
      "Train mae :  0.5729256779607267\n",
      "Test  mae :  0.6314134327036903\n",
      "\n",
      "\n",
      "Model: RidgeCV\n",
      "\n",
      "Train r2  :  0.2879408848619589\n",
      "Test  r2  :  0.25096959742516267\n",
      "\n",
      "Train mae :  0.5729256779607212\n",
      "Test  mae :  0.6314134327037204\n",
      "\n",
      "\n",
      "Model: SGDRegressor\n",
      "\n",
      "Train r2  :  0.2838101020762188\n",
      "Test  r2  :  0.2528103503017597\n",
      "\n",
      "Train mae :  0.5758012804133518\n",
      "Test  mae :  0.6336038280503943\n",
      "\n",
      "\n",
      "Model: Lasso\n",
      "\n",
      "Train r2  :  0.0\n",
      "Test  r2  :  -0.005656503687872849\n",
      "\n",
      "Train mae :  0.6535309995802152\n",
      "Test  mae :  0.7164796699690595\n",
      "\n",
      "\n",
      "Model: ElasticNet\n",
      "\n",
      "Train r2  :  0.0\n",
      "Test  r2  :  -0.005656503687872849\n",
      "\n",
      "Train mae :  0.6535309995802152\n",
      "Test  mae :  0.7164796699690595\n",
      "\n",
      "\n",
      "Model: HuberRegressor\n",
      "\n",
      "Train r2  :  0.2855640385989474\n",
      "Test  r2  :  0.25403100779974286\n",
      "\n",
      "Train mae :  0.5722018489719723\n",
      "Test  mae :  0.6292486396404636\n",
      "\n",
      "\n",
      "Model: LinearSVR\n",
      "\n",
      "Train r2  :  0.2810878685033662\n",
      "Test  r2  :  0.25199469691416754\n",
      "\n",
      "Train mae :  0.570024821049799\n",
      "Test  mae :  0.6281626878055454\n",
      "\n",
      "\n",
      "Model: ExtraTreeRegressor\n",
      "\n",
      "Train r2  :  1.0\n",
      "Test  r2  :  -0.08364688856729408\n",
      "\n",
      "Train mae :  0.0\n",
      "Test  mae :  0.6122448979591837\n",
      "\n",
      "\n",
      "Model: DecisionTreeRegressor\n",
      "\n",
      "Train r2  :  1.0\n",
      "Test  r2  :  -0.060492040520984336\n",
      "\n",
      "Train mae :  0.0\n",
      "Test  mae :  0.5836734693877551\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best   r2_train :  ExtraTreeRegressor   1.0\n",
      "\n",
      "Best   r2_test :  HuberRegressor   0.25403100779974286\n",
      "\n",
      "Best Train  MAE :  ExtraTreeRegressor   0.0\n",
      "\n",
      "Best Test   MAE :  DecisionTreeRegressor   0.5836734693877551\n",
      "\n",
      "Models with Over-fittings ['ExtraTreeRegressor', 'DecisionTreeRegressor']\n",
      "\n",
      "Models with Under-fittings ['LinearRegression', 'Ridge', 'RidgeCV', 'SGDRegressor', 'Lasso', 'ElasticNet', 'HuberRegressor', 'LinearSVR']\n"
     ]
    }
   ],
   "source": [
    "run_models(linear_models,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "NuSVR = sklearn.svm.NuSVR()\n",
    "ESVR = sklearn.svm.SVR()\n",
    "RFR = ensemble.RandomForestRegressor()\n",
    "Ada = ensemble.AdaBoostRegressor()\n",
    "XGB = xgboost.XGBRegressor()\n",
    "non_linear_models = [RFR,XGB,NuSVR,ESVR,Ada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model: RandomForestRegressor\n",
      "\n",
      "Train R2  :  0.9348320572542389\n",
      "Test  R2  :  0.9348320572542389\n",
      "\n",
      "Train mae :  0.15634762633996932\n",
      "Test  mae :  0.5247448979591837\n",
      "\n",
      "\n",
      "Model: XGBRegressor\n",
      "\n",
      "Train R2  :  0.9405719496284562\n",
      "Test  R2  :  0.9405719496284562\n",
      "\n",
      "Train mae :  0.1479305915530693\n",
      "Test  mae :  0.557083260039894\n",
      "\n",
      "\n",
      "Model: NuSVR\n",
      "\n",
      "Train R2  :  0.4844599653533134\n",
      "Test  R2  :  0.4844599653533134\n",
      "\n",
      "Train mae :  0.49715574570701\n",
      "Test  mae :  0.5905932715061741\n",
      "\n",
      "\n",
      "Model: SVR\n",
      "\n",
      "Train R2  :  0.498578529479269\n",
      "Test  R2  :  0.498578529479269\n",
      "\n",
      "Train mae :  0.4463006214440417\n",
      "Test  mae :  0.5613065611105376\n",
      "\n",
      "\n",
      "Model: AdaBoostRegressor\n",
      "\n",
      "Train R2  :  0.33915274794057126\n",
      "Test  R2  :  0.33915274794057126\n",
      "\n",
      "Train mae :  0.5699032857170218\n",
      "Test  mae :  0.6362242938253484\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Best   R2_train :  XGBRegressor   0.9405719496284562\n",
      "\n",
      "Best   R2_test :  XGBRegressor   0.9405719496284562\n",
      "\n",
      "Best Train  MAE :  XGBRegressor   0.1479305915530693\n",
      "\n",
      "Best Test   MAE :  RandomForestRegressor   0.5247448979591837\n",
      "\n",
      "Models with Over-fittings ['RandomForestRegressor', 'XGBRegressor']\n"
     ]
    }
   ],
   "source": [
    "run_models(non_linear_models,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
